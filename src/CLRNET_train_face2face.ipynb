{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Import Python Packages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# from tensorflow_core.python.keras.callbacks import ModelCheckpoint\n",
    "# from tensorflow_core.python.keras.utils.data_utils import Sequence\n",
    "# from tensorflow_core.python.keras.utils.layer_utils import print_summary\n",
    "# from tensorflow_core.python.keras.utils.np_utils import to_categorical\n",
    "from tensorflow.python.keras.backend import clear_session\n",
    "from tensorflow.python.keras.callbacks import ModelCheckpoint, CSVLogger\n",
    "from tensorflow.python.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.python.keras.utils import Sequence, to_categorical\n",
    "from tensorflow.python.keras.utils.layer_utils import print_summary\n",
    "from tensorflow.python.keras.optimizers import Adam\n",
    "from tensorflow.python.keras.models import load_model\n",
    "\n",
    "print(\"yolo\")\n",
    "import os\n",
    "\n",
    "import glob\n",
    "# from mtcnn.mtcnn import MTCNN\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import shutil\n",
    "from CLRNet_convlstm import CLRNet\n",
    "# from src.xception_convlstm import Xception\n",
    "# print(cv2.__version__)\n",
    "from PIL import Image\n",
    "import random\n",
    "from sklearn.utils import class_weight\n",
    "from datetime import datetime as dt\n",
    "import natsort\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "random.seed(32)\n",
    "dataset_dir='DeepFakeDatasetReal'\n",
    "# from src.cl_basic import cl_basic\n",
    "import ipykernel\n",
    "import os\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\";\n",
    " \n",
    "# Choose GPU NUMBERS [0, 1, 2, 3]\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.Session(config=config)\n",
    "K.set_session(sess)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DFVDSequence Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#   Here, `x_set` is list of path to the images,\n",
    "#   `y_set` are the associated classes,\n",
    "#   'v' is the no. of videos for each batch\n",
    "#   and fpv is the no. of frames from each video\n",
    "class DFVDSequence(Sequence):\n",
    "    def __init__(self, x_set, y_set,v,fpv,image_size=240):\n",
    "        self.x, self.y = x_set, y_set\n",
    "        self.batch_size = fpv*v\n",
    "        self.count=0\n",
    "        self.video_iterator=0\n",
    "        self.frame_iterator=0\n",
    "        self.v=v\n",
    "        self.fpv=fpv\n",
    "        self.dataset_size=sum([len(value) for key, value in self.x.items()])\n",
    "        self.frame_counter=0\n",
    "        self.on_epoch_end()\n",
    "        self.image_size=image_size\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(self.dataset_size / float(self.batch_size)))\n",
    "    def resize_img(self,img,basewidth=240):\n",
    "        wpercent = (basewidth/float(img.size[0]))\n",
    "        hsize = int((float(img.size[1])*float(wpercent)))\n",
    "#         img = img.resize((basewidth,hsize), Image.ANTIALIAS)\n",
    "        img = img.resize((basewidth,basewidth), Image.ANTIALIAS)\n",
    "        return img\n",
    "    \n",
    "    def img_transf(self,img):\n",
    "        img -= img.mean()\n",
    "        img /= np.maximum(img.std(), 1/image_size**2) #prevent /0\n",
    "        return img  \n",
    "        \n",
    "    def __getitem__(self,idx):\n",
    "        batch_x=[]\n",
    "        batch_y = []\n",
    "        video_idx=0\n",
    "        _iter=0\n",
    "        while _iter < self.v:\n",
    "            _iter+=1\n",
    "            if self.frame_counter >= self.dataset_size:\n",
    "                self.on_epoch_end()\n",
    "                print('*',end=\",\")\n",
    "                _iter-=1\n",
    "                continue\n",
    "            frames2read=self.x[str(self.video_iterator)][self.frame_iterator:self.frame_iterator+self.fpv]\n",
    "            temp_frames=[]\n",
    "            img_gen = ImageDataGenerator(rotation_range=30,\n",
    "                                         samplewise_center=True,\n",
    "                                         samplewise_std_normalization=True,\n",
    "                                        # width_shift_range=0.2,\n",
    "                                        # height_shift_range=0.2,\n",
    "                                        # rescale=1./255,\n",
    "                                        brightness_range=[0.7,1.0],\n",
    "                                        channel_shift_range=50.0,\n",
    "                                        # shear_range=0.1,\n",
    "                                        zoom_range=0.2,\n",
    "                                        horizontal_flip=True,\n",
    "#                                         vertical_flip = True,\n",
    "                                        fill_mode='nearest')\n",
    "            transform_param=img_gen.get_random_transform(img_shape=(self.image_size,self.image_size,3), seed=None)\n",
    "#             print(transform_param)\n",
    "            if len(frames2read)>=self.fpv:\n",
    "                for frame in frames2read:                    \n",
    "                    _image=cv2.imread(frame)\n",
    "                    _image=cv2.cvtColor(_image, cv2.COLOR_BGR2RGB).astype('float64')\n",
    "                    _image=cv2.resize(_image,(self.image_size,self.image_size))\n",
    "                    _image=img_gen.apply_transform(_image,transform_param)\n",
    "                    _image/=255\n",
    "                    temp_frames.append(np.asarray(_image))\n",
    "                batch_x.append(temp_frames)\n",
    "                batch_y.append(self.y[self.video_iterator])\n",
    "            else:\n",
    "                _iter-=1\n",
    "            self.video_iterator+=1\n",
    "            self.frame_counter+=len(frames2read)\n",
    "            if self.video_iterator % len(self.x) ==0:\n",
    "                self.video_iterator=0\n",
    "                self.frame_iterator+=len(frames2read)\n",
    "            video_idx+=1\n",
    "        if self.video_iterator % len(self.x) == 0:\n",
    "            self.video_iterator=0\n",
    "        if len(batch_y)>0:\n",
    "            batch_y=to_categorical(batch_y,2)\n",
    "            batch_x=np.array(batch_x)\n",
    "        return (batch_x,batch_y)\n",
    "    def on_epoch_end(self):\n",
    "        \"\"\" Method called at the end of every epoch. \"\"\"\n",
    "        self.count=0\n",
    "        self.video_iterator=0\n",
    "        self.frame_iterator=0\n",
    "        self.frame_counter=0\n",
    "        return\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Sequence Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def downsample_withoutshuffle(f_list,fpvpb,no_frames):\n",
    "    f_list=natsort.natsorted(f_list)\n",
    "    _total=int(no_frames/fpvpb)# 20/5\n",
    "    _tempList=[]\n",
    "    # print(\"Size:\",_total)\n",
    "    if len(f_list)>_total:#if list smaller than required frames\n",
    "        for i in range (0,_total):\n",
    "            _range=len(f_list)-fpvpb\n",
    "            if _range==0:\n",
    "                return f_list\n",
    "            x=random.randrange(_range)\n",
    "            for j in range(0, fpvpb):\n",
    "                # print(os.path.splitext(os.path.basename(f_list[x+j]))[0],end=\",\")\n",
    "                _tempList.append(f_list[x+j])\n",
    "            # print()\n",
    "        return _tempList\n",
    "    else:\n",
    "        return f_list\n",
    "    \n",
    "def create_sequence(dir,fpvpb,no_frames):\n",
    "    random.seed(35)\n",
    "    count_real=0\n",
    "    count_fake=0\n",
    "    folders = [i for i in sorted(glob.glob(os.path.join(dir,'*',\"*\")))]\n",
    "    total_folders=len(folders)\n",
    "    X={}\n",
    "    y = []\n",
    "    print('Total Video Folders Found (Real + Fake):',total_folders)\n",
    "    pre_folder=-1\n",
    "    i=0\n",
    "    _downsampled=[]\n",
    "    while i<total_folders:\n",
    "        folder=random.choice(folders)\n",
    "        dir_name=os.path.dirname(folder)\n",
    "        folder_name=os.path.basename(dir_name)\n",
    "#         print(folder_name)\n",
    "        _downsampled=[x for x in sorted(glob.glob(os.path.join(folder,\"*\")))]\n",
    "#         _downsampled=downsample_withoutshuffle([x for x in sorted(glob.glob(os.path.join(folder,\"*\")))],fpvpb,no_frames)\n",
    "        if folder_name=='real':\n",
    "            if pre_folder == 1:\n",
    "                continue\n",
    "            y.append(1)\n",
    "            count_real+=len(_downsampled)\n",
    "            pre_folder = 1\n",
    "        elif folder_name=='fake':\n",
    "            if pre_folder == 0:\n",
    "                continue\n",
    "            y.append(0)\n",
    "            count_fake+=len(_downsampled)\n",
    "            pre_folder = 0\n",
    "        else:\n",
    "            print(\"Directory names should be 'real' for label (1) and 'fake' for label (0)\")\n",
    "            exit(0)\n",
    "        # X[str(i)]=[x for x in sorted(glob.glob(os.path.join(folder,\"*\")))]\n",
    "        X[str(i)]=_downsampled\n",
    "        folders.remove(folder)\n",
    "        i+=1\n",
    "    print('Real Frames:',count_real,'Fake Frames:',count_fake)\n",
    "    labels=[]\n",
    "    for i in range(0,count_real):\n",
    "        labels.append(1)\n",
    "    for i in range(0,count_fake):\n",
    "        labels.append(0)\n",
    "    y_ints = [v.argmax() for v in to_categorical(labels)]\n",
    "    class_weights = class_weight.compute_class_weight('balanced', np.unique(y_ints), y_ints)\n",
    "    print('Class Weights:',class_weights)\n",
    "    return X,y, class_weights\n",
    "\n",
    "train_video_per_batch=16\n",
    "val_video_per_batch=16\n",
    "test_video_per_batch=16\n",
    "frames_per_video=80 #total frames\n",
    "frames_per_video_per_batch=5 #frames in one batch\n",
    "image_size=240\n",
    "channel=3\n",
    "X_train,y_train, class_weights_train =create_sequence('datasets/Face2Face/train/',frames_per_video_per_batch,frames_per_video)\n",
    "X_val,y_val,class_weights_val=create_sequence('datasets/Face2Face/val/',frames_per_video_per_batch,frames_per_video)\n",
    "# X_test,y_test,class_weights_test=create_sequence('datasets/Face2Face/test/',frames_per_video_per_batch,frames_per_video)\n",
    "train_it=DFVDSequence(X_train,y_train,train_video_per_batch,frames_per_video_per_batch,image_size)\n",
    "val_it=DFVDSequence(X_val,y_val,val_video_per_batch,frames_per_video_per_batch,image_size)\n",
    "# test_it=DFVDSequence(X_test,y_test,test_video_per_batch,frames_per_video_per_batch,image_size)\n",
    "\n",
    "fig=plt.figure(figsize=(10, 100))\n",
    "columns = 4\n",
    "rows = 23\n",
    "\n",
    "print(\"Training\")\n",
    "x=1\n",
    "temp=train_it.__getitem__(1)\n",
    "fig.add_subplot(rows, columns, x)\n",
    "print(\"Min:\",np.array(temp[0][0,0]).min(),\"Max:\",np.array(temp[0][0,0]).max())\n",
    "print(\"Min:\",np.array(temp[0][1,0]).min(),\"Max:\",np.array(temp[0][1,0]).max())\n",
    "plt.imshow(np.array(temp[0][0,0]))\n",
    "fig.add_subplot(rows, columns, x+1)\n",
    "plt.imshow(np.array(temp[0][1,0]))\n",
    "print(temp[0].shape,temp[1].shape,train_it.dataset_size,train_it.frame_counter,train_it.__len__(),temp[1][0],temp[1][1])\n",
    "# x+=2\n",
    "plt.title(\"Training Set Examples\")        \n",
    "plt.show()\n",
    "train_it.on_epoch_end()\n",
    "fig=plt.figure(figsize=(10, 100))\n",
    "columns = 4\n",
    "rows = 23\n",
    "\n",
    "print(\"Validation\")\n",
    "x=1\n",
    "temp=val_it.__getitem__(1)\n",
    "fig.add_subplot(rows, columns, x)\n",
    "print(\"Min:\",np.array(temp[0][0,0]).min(),\"Max:\",np.array(temp[0][0,0]).max())\n",
    "print(\"Min:\",np.array(temp[0][1,0]).min(),\"Max:\",np.array(temp[0][1,0]).max())\n",
    "plt.imshow(np.array(temp[0][0,0]),)\n",
    "fig.add_subplot(rows, columns, x+1)\n",
    "plt.imshow(np.array(temp[0][1,0]))\n",
    "print(temp[0].shape,temp[1].shape,val_it.dataset_size,val_it.frame_counter,val_it.__len__(),temp[1][0],temp[1][1])\n",
    "plt.title(\"Validation Set Examples\")   \n",
    "plt.show()\n",
    "val_it.on_epoch_end()\n",
    "                                                                                                            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "model=CLRNet(input_shape=(frames_per_video_per_batch,image_size, image_size, channel), classes=2, block='bottleneck', residual_unit='v2',\n",
    "           repetitions=[3, 4, 6, 3], initial_filters=64, activation='softmax', include_top=False,\n",
    "           input_tensor=None, dropout=0.25, transition_dilation_rate=(1, 1),\n",
    "           initial_strides=(2, 2), initial_kernel_size=(7, 7), initial_pooling='max',\n",
    "           final_pooling=None, top='classification')\n",
    "print_summary(model, line_length=150, positions=None, print_fn=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "adam_fine = Adam(lr=0.00005, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "# model.compile(loss='binary_crossentropy',\n",
    "#                   optimizer='adam',\n",
    "#                   metrics=['accuracy'])\n",
    "model.compile(loss='binary_crossentropy',\n",
    "                  optimizer=adam_fine,\n",
    "                  metrics=['accuracy'])\n",
    "# os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\";\n",
    "# Choose GPU NUMBERS [0, 1, 2, 3]\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.Session(config=config)\n",
    "K.set_session(sess)\n",
    "# _id = dt.now().strftime(\"%y-%m-%d-%H_%M\")\n",
    "# os.path.join('models','df_CLRNet50(bk)_',_id)\n",
    "_id = dt.now().strftime(\"%y-%m-%d-%H_%M\")\n",
    "save_dir=os.path.join(os.getcwd(),'models','Face2Face','CLRNet50(bk)',_id)\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "\n",
    "\n",
    "filepath=os.path.join(save_dir,\"{epoch:02d}-{acc:.2f}\"+\".hdf5\")\n",
    "checkpoint = ModelCheckpoint(filepath)#, monitor='acc', verbose=2, save_best_only=True, mode='max')\n",
    "csv_logger = CSVLogger(os.path.join(save_dir,\"training.csv\"), append=True, separator=',')\n",
    "\n",
    "# filepath=os.path.join('models','df_CLRNet50(bk)_'+_id+\"-{epoch:02d}-{acc:.2f}\"\n",
    "# checkpoint = ModelCheckpoint(str(filepath)+\".hdf5\")#, monitor='acc', verbose=2, save_best_only=True, mode='max')\n",
    "# csv_logger = CSVLogger('df_CLRNet50(bk)_'+str(_id)+\".csv\", append=True, separator=',')\n",
    "# earlyStop=EarlyStopping(monitor='val_loss', min_delta=0, patience=0, verbose=0, mode='auto', baseline=None, restore_best_weights=False)\n",
    "callbacks_list = [checkpoint,csv_logger]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.fit_generator(generator=train_it, validation_data=val_it,epochs=300,\n",
    "                    callbacks=callbacks_list,shuffle=False,class_weight=class_weights_train,verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load model from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# model = load_model('CLRNet50(bk)_19-12-11-12_38-150-1.00.hdf5')\n",
    "# adam_fine = Adam(lr=0.00005, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "# model.compile(loss='binary_crossentropy',\n",
    "#                   optimizer=adam_fine,\n",
    "#                   metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# test Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "X_test,y_test,class_weights_test=create_sequence('datasets/Face2Face/test/',frames_per_video_per_batch,frames_per_video)\n",
    "test_it=DFVDSequence(X_test,y_test,test_video_per_batch,frames_per_video_per_batch)\n",
    "# for i in range(0,test_it.__len__()):\n",
    "#     temp=test_it.__getitem__(1)\n",
    "#     print(temp[0].shape,temp[1].shape,test_it.dataset_size,test_it.frame_counter)\n",
    "# # model.load_weights('2019-11-01_16.57.45_weights-improvement-01-1.00.hdf5')\n",
    "# model.compile(loss='binary_crossentropy',\n",
    "#                   optimizer='adam',\n",
    "#                   metrics=['accuracy'])\n",
    "print(model.evaluate_generator(test_it))\n",
    "test_it=DFVDSequence(X_test,y_test,test_video_per_batch,frames_per_video_per_batch)\n",
    "y_prob=model.predict_generator(test_it)\n",
    "y_classes = y_prob.argmax(axis=-1)\n",
    "print(y_classes)\n",
    "y_prob=model.predict_generator(test_it)\n",
    "y_classes = y_prob.argmax(axis=-1)\n",
    "print(y_classes)\n",
    "# print('test loss:',loss)\n",
    "# model=cl_basic(128,128,3,2)\n",
    "# print_summary(model, line_length=150, positions=None, print_fn=None)\n",
    "# model.compile(loss='binary_crossentropy',\n",
    "#                   optimizer='adam',\n",
    "#                   metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "test_it=DFVDSequence(X_test,y_test,test_video_per_batch,frames_per_video_per_batch)\n",
    "y_prob = model.evaluate_generator(test_it)\n",
    "print(y_prob)\n",
    "# y_classes = y_prob.argmax(axis=-1)\n",
    "# print(y_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# model.fit_generator(generator=train_it, validation_data=val_it,epochs=150,initial_epoch=50,\n",
    "                    callbacks=callbacks_list,shuffle=False,class_weight=class_weights_train,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _id = dt.now().strftime(\"%y-%m-%d-%H_%M\")\n",
    "# print(_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.fit_generator(generator=train_it, validation_data=val_it,epochs=300,initial_epoch=150,\n",
    "#                     callbacks=callbacks_list,shuffle=False,class_weight=class_weights_train,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "_id = dt.now().strftime(\"%y-%m-%d-%H_%M\")\n",
    "save_dir=os.path.join(os.getcwd(),'models','Face2Face','CLRNet50(bk)',_id)\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}